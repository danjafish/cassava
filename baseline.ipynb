{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import timm\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold = 0\n",
    "#img_size = 512\n",
    "#bs = 16\n",
    "epochs_to_predict = [7,8,9]\n",
    "LOG_FILE = f\"distil_03_07.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 0,\n",
    "    'seed': 2021,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 16,\n",
    "    'valid_bs': 32,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 8,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'fp16': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_AUGS = Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "VAL_AUGS =  Compose([\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "TEST_AUGS =  Compose([\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "# Worth trying: Blur, Noize,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n",
    "\n",
    "seed_everything(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21397, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/data/Cassava/train.csv')\n",
    "print(data.shape)\n",
    "# data.label.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = json.load(open('/home/data/Cassava/label_num_to_disease_map.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4280\n",
       "0    4280\n",
       "4    4279\n",
       "3    4279\n",
       "2    4279\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fold'] = 0\n",
    "#add random state\n",
    "strkf = StratifiedKFold(n_splits=5)\n",
    "_ =strkf.get_n_splits(data.image_id, data.label)\n",
    "f = 0\n",
    "for train_index, test_index in strkf.split(data.image_id, data.label):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    data.loc[data.index.isin(test_index), 'fold'] = f \n",
    "    f = f+1\n",
    "data.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, mode = 'train'):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[self.df.index == idx]\n",
    "        image_name = row.image_id.values[0]\n",
    "        img = get_img('/home/data/Cassava/train_images/'+ image_name)\n",
    "        if self.mode == 'train':\n",
    "            label = row.label.values[0]\n",
    "            img = TRAIN_AUGS(image=img)['image']\n",
    "            #img = np.moveaxis(img, 2, 0)\n",
    "            return img, label\n",
    "        elif self.mode == 'val':\n",
    "            label = row.label.values[0]\n",
    "            img = VAL_AUGS(image=img)['image']\n",
    "            return img, label\n",
    "        elif self.mode == 'test':\n",
    "            img = TEST_AUGS(image=img)['image']\n",
    "            return img\n",
    "        else:\n",
    "            print(\"Unknown mod type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optim, train_loader, loss_fn, epoch):\n",
    "    model = model.train();\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True)\n",
    "    for step, (x, y_true) in pbar:\n",
    "        x = x.to(device).float()\n",
    "        y_true = y_true.to(device).long()\n",
    "        y_pred = model(x)\n",
    "        l = loss_fn(y_pred, y_true)\n",
    "        optim.zero_grad()\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n",
    "        targets_all += [y_true.detach().cpu().numpy()]\n",
    "        if running_loss is None:\n",
    "            running_loss = l.item()\n",
    "        else:\n",
    "            running_loss = running_loss * .99 + l.item() * .01\n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            description = f'tain epoch {epoch} loss: {running_loss:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "    print(\"Target acc = \", (preds_all==targets_all).mean())\n",
    "    with open(LOG_FILE, 'a+') as logger:\n",
    "        logger.write(f\"Epoch # {epoch}, train acc = {(preds_all==targets_all).mean()}, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(model, optim, val_loader, loss_fn, epoch):\n",
    "    preds_all = []\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    with torch.no_grad():\n",
    "        model = model.eval();\n",
    "        for step, (x, y_true) in pbar:\n",
    "            x = x.to(device).float()\n",
    "            y_true = y_true.to(device).long()\n",
    "            y_pred = model(x)\n",
    "            preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n",
    "            targets_all += [y_true.detach().cpu().numpy()]\n",
    "            l = loss_fn(y_pred, y_true)\n",
    "            loss_sum += l.item()*y_true.shape[0]\n",
    "            sample_num += y_true.shape[0]  \n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            description = f'val epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "    print('validation multi-class accuracy = {:.4f}'.format((preds_all==targets_all).mean()))\n",
    "    with open(LOG_FILE, 'a+') as logger:\n",
    "        logger.write(f\"val acc = {(preds_all==targets_all).mean()}\\n\")\n",
    "    return (preds_all==targets_all).mean(), loss_sum/sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(torch.nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for dev_fold in [1,2,3,4]:\n",
    "#     train_data = data[(data.fold != test_fold) & (data.fold != dev_fold)].reset_index(drop=True)\n",
    "#     val_data = data[data.fold == test_fold].reset_index(drop=True)\n",
    "#     dev_data = data[data.fold == dev_fold].reset_index(drop=True)  \n",
    "    \n",
    "#     train_ds = CassavaDataset(train_data, mode = 'train')\n",
    "#     dev_ds = CassavaDataset(val_data, mode = 'val')\n",
    "#     valid_ds = CassavaDataset(val_data, mode = 'val')\n",
    "    \n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#         train_ds,\n",
    "#         batch_size=CFG['train_bs'],\n",
    "#         pin_memory=False,\n",
    "#         drop_last=False,\n",
    "#         shuffle=True,        \n",
    "#         num_workers=8)\n",
    "    \n",
    "#     val_loader = torch.utils.data.DataLoader(\n",
    "#         valid_ds, \n",
    "#         batch_size=CFG['valid_bs'],\n",
    "#         num_workers=8,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=False)\n",
    "    \n",
    "#     dev_loader = torch.utils.data.DataLoader(\n",
    "#         dev_ds, \n",
    "#         batch_size=CFG['valid_bs'],\n",
    "#         num_workers=8,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=False)\n",
    "    \n",
    "#     model = CassvaImgClassifier('tf_efficientnet_b4_ns', data.label.nunique(), pretrained=True).to(device)\n",
    "    \n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay=1e-6)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['epochs'], T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "    \n",
    "#     loss_tr = nn.CrossEntropyLoss().to(device)\n",
    "#     loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "#     for epoch in range(CFG['epochs']):\n",
    "#         print(f\"epoch number {epoch}, lr = {optimizer.param_groups[0]['lr']}\")\n",
    "#         train_one_epoch(model, optimizer, train_loader, loss_tr, epoch)\n",
    "#         val_acc, val_loss = valid_one_epoch(model, optimizer, val_loader, loss_fn, epoch)\n",
    "\n",
    "#         torch.save(model.state_dict(),'./output/{}_dev_fold_{}_test_fold_{}_epoch_{}_val_loss_{:.4f}_val_acc_{:.4f}'.format(CFG['model_arch'], dev_fold, test_fold, epoch, val_acc, val_loss))\n",
    "\n",
    "#     #del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = [\n",
    "        \"/home/samenko/Cassava/output/tf_efficientnet_b4_ns_dev_fold_1_test_fold_0_epoch_5_val_loss_0.8820_val_acc_0.3677\",\n",
    "        \"/home/samenko/Cassava/output/tf_efficientnet_b4_ns_dev_fold_2_test_fold_0_epoch_4_val_loss_0.8825_val_acc_0.3624\",\n",
    "        \"/home/samenko/Cassava/output/tf_efficientnet_b4_ns_dev_fold_3_test_fold_0_epoch_6_val_loss_0.8825_val_acc_0.3679\",\n",
    "        \"/home/samenko/Cassava/output/tf_efficientnet_b4_ns_dev_fold_4_test_fold_0_epoch_5_val_loss_0.8811_val_acc_0.3739\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_cp = []\n",
    "# for dev_fold in [1,2,3,4]:\n",
    "#     print(f\"dev fold: {dev_fold}\")\n",
    "#     dev_data = data[data.fold == dev_fold].reset_index(drop=True)  \n",
    "#     dev_data_cp = dev_data.copy()\n",
    "#     dev_ds = CassavaDataset(dev_data, mode = 'val')\n",
    "\n",
    "    \n",
    "#     dev_loader = torch.utils.data.DataLoader(\n",
    "#         dev_ds, \n",
    "#         batch_size=CFG['valid_bs'],\n",
    "#         num_workers=8,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=False)    \n",
    "#     submission = []\n",
    "#     model = CassvaImgClassifier('tf_efficientnet_b4_ns', data.label.nunique(), pretrained=True).to(device)\n",
    "#     _ = model.load_state_dict(torch.load(PATH[dev_fold - 1]))\n",
    "    \n",
    "#     dev_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for image, label in tqdm(dev_loader):\n",
    "#             dev_preds.append(model(image.to(\"cuda\")))\n",
    "\n",
    "#         dev_preds = torch.cat(dev_preds)\n",
    "#         submission.append(dev_preds.cpu().numpy())\n",
    "#     submission_ensembled = 0\n",
    "#     for sub in submission:\n",
    "#         submission_ensembled += softmax(sub, axis=1) / len(submission)\n",
    "#     for columnID in range(submission_ensembled.shape[1]):\n",
    "#         dev_data_cp[columnID] = submission_ensembled[:,columnID]    \n",
    "#     train_data_cp.append(dev_data_cp)\n",
    "# soft_labels = data[[\"image_id\"]].merge(pd.concat(train_data_cp), how=\"left\", on=\"image_id\")\n",
    "# soft_labels.to_csv(\"./tmp/soft_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_labels = pd.read_csv('./tmp/soft_labels.csv')\n",
    "soft_labels = soft_labels.dropna()\n",
    "soft_labels.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft_labels['predic_label']= soft_labels.apply(lambda x:np.argmax(x.values[3:8]),axis=1)\n",
    "# soft_labels['max_prob']= soft_labels.apply(lambda x : max(x.values[3:8]),axis=1)\n",
    "\n",
    "# soft_labels['drop'] = (soft_labels['label'] != soft_labels['predic_label']) &  (soft_labels['max_prob'] > 0.95)\n",
    "# soft_labels['drop'].sum()\n",
    "\n",
    "# clean_soft =soft_labels[~soft_labels['drop']][['image_id','label','fold','0','1','2','3','4']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossOneHot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLossOneHot, self).__init__()\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "        return torch.mean(torch.sum(-labels * self.log_softmax(preds), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_soft(model, optim, train_loader, loss_fn, epoch):\n",
    "    model = model.train();\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True)\n",
    "    for step, (x, y_true) in pbar:\n",
    "        x = x.to(device).float()\n",
    "        y_true = y_true.to(device)\n",
    "        y_pred = model(x)\n",
    "        l = loss_fn(y_pred, y_true.float())\n",
    "        optim.zero_grad()\n",
    "        if CFG['fp16']:\n",
    "            with apex.amp.scale_loss(l, optim) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            l.backward()\n",
    "        optim.step()\n",
    "        preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n",
    "        targets_all += [torch.argmax(y_true, 1).detach().cpu().numpy()]\n",
    "        if running_loss is None:\n",
    "            running_loss = l.item()\n",
    "        else:\n",
    "            running_loss = running_loss * .99 + l.item() * .01\n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            description = f'tain epoch {epoch} loss: {running_loss:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "    print(\"Target acc = \", (preds_all==targets_all).mean())\n",
    "    with open(LOG_FILE, 'a+') as logger:\n",
    "        logger.write(f\"Epoch # {epoch}, train acc = {(preds_all==targets_all).mean()}, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cassava_Soft_Dataset(Dataset):\n",
    "    def __init__(self, df, mode = 'train'):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "    def to_one_hot(self, le_label, num_classes = 5):\n",
    "        oho_label = np.zeros(num_classes)\n",
    "        oho_label[int(le_label)] = 1\n",
    "        return oho_label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[self.df.index == idx]\n",
    "        image_name = row.image_id.values[0]\n",
    "        img = get_img('/home/data/Cassava/train_images/'+ image_name)\n",
    "        if self.mode == 'train':\n",
    "            label = self.to_one_hot(row.label.values[0])\n",
    "            soft_labels = row.values[0][3:]\n",
    "            label = (label*0.7).astype(float) + (soft_labels * 0.3).astype(float)\n",
    "            img = TRAIN_AUGS(image=img)['image']\n",
    "            #img = np.moveaxis(img, 2, 0)\n",
    "            return img, label\n",
    "        elif self.mode == 'val':\n",
    "            label = self.to_one_hot(row.label.values[0])\n",
    "            soft_labels = row.values[0][3:]\n",
    "            label = (label*0.7).astype(float) + (soft_labels * 0.3).astype(float)\n",
    "            img = VAL_AUGS(image=img)['image']\n",
    "            return img, label\n",
    "        elif self.mode == 'val_test':\n",
    "            label = row.label.values[0]\n",
    "            img = VAL_AUGS(image=img)['image']\n",
    "            return img, label\n",
    "        elif self.mode == 'test':\n",
    "            img = TEST_AUGS(image=img)['image']\n",
    "            return img\n",
    "        else:\n",
    "            print(\"Unknown mod type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "# train_data = clean_soft[(clean_soft.fold != test_fold)].reset_index(drop=True)\n",
    "train_data = soft_labels[(soft_labels.fold != test_fold)].reset_index(drop=True)\n",
    "\n",
    "val_data = data[data.fold == test_fold].reset_index(drop=True)\n",
    "train_ds = Cassava_Soft_Dataset(train_data, mode = 'train')\n",
    "valid_ds = Cassava_Soft_Dataset(val_data, mode = 'val_test')\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=8)\n",
    "    \n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "        pin_memory=False)\n",
    "\n",
    "    \n",
    "model = CassvaImgClassifier('tf_efficientnet_b4_ns', data.label.nunique(), pretrained=True).to(device)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['epochs'], T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "    \n",
    "#loss_tr = nn.CrossEntropyLoss().to(device)\n",
    "#loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "loss_tr = loss_fn = CrossEntropyLossOneHot().to(device)\n",
    "loss_val = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "if CFG['fp16']:\n",
    "    model, optimizer = apex.amp.initialize(\n",
    "        model,\n",
    "        optimizer,\n",
    "        opt_level='O1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0, lr = 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/jupyterhub/0.8.1/lib/python3.6/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1281e5cf944a1e825e768975627f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.8148039960273412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/jupyterhub/0.8.1/lib/python3.6/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5163bee645d4df8af31e8c6171f9041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8654\n",
      "epoch number 1, lr = 9.757729755661011e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c25c583082c44a89378b4960082a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "Target acc =  0.8637611731027633\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350110d277a84e5aa9132e1906acffd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8822\n",
      "epoch number 2, lr = 9.05463412215599e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dac548f1d6f4f78bca54c7507650fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "Target acc =  0.8752117777647952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddafd79db4dc4c20a1e3666e1e99aaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8834\n",
      "epoch number 3, lr = 7.959536998847742e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4703d9f2088840ec817137f236449510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.8866623824268272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d4ab89ce8b47308bdb3692a227bd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8827\n",
      "epoch number 4, lr = 6.57963412215599e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c73292650314e05ae95391454fd8d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.8881813401881171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff0451ff7cf40f9b881abdc290ecc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8860\n",
      "epoch number 5, lr = 5.05e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826ea3e8e8b04300b27b890c1c3b5edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.8969445580417129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61da34e091743dea8c1daa10e3f7ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8836\n",
      "epoch number 6, lr = 3.5203658778440106e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d6afd61d414ee282ec987fd70a4aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.9027867032774435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ce668b7d5345549d2b3588c18217a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8841\n",
      "epoch number 7, lr = 2.1404630011522586e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a130404c6148629f2772dcf5675111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "Target acc =  0.9074019980136706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534c908b87c44354b9fd7e54669e859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8829\n",
      "epoch number 8, lr = 1.0453658778440109e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928e73c53ab2435d99ea2e87193a0d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.9112578138692528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a52184fa36417bb5fc6d1b639bd04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8860\n",
      "epoch number 9, lr = 3.4227024433899e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5ea72d7752446395567edfa618b0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target acc =  0.9140620435824035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebe690be3d74a1ebfb9bbdfa16ec370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation multi-class accuracy = 0.8839\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(CFG['epochs']):\n",
    "    print(f\"epoch number {epoch}, lr = {optimizer.param_groups[0]['lr']}\")\n",
    "    train_one_epoch_soft(model, optimizer, train_loader, loss_tr, epoch)\n",
    "    val_acc, val_loss = valid_one_epoch(model, optimizer, val_loader, loss_val, epoch)\n",
    "\n",
    "    #torch.save(model.state_dict(),'./output/{}_soft_dev_fold_{}_test_fold_{}_epoch_{}_val_loss_{:.4f}_val_acc_{:.4f}'.format(CFG['model_arch'], dev_fold, test_fold, epoch, val_acc, val_loss))\n",
    "\n",
    "#del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
